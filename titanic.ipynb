{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# titanic data","metadata":{}},{"cell_type":"markdown","source":"Najpierw zaloguj się do https://www.kaggle.com/ i przejdź do wyzwania https://www.kaggle.com/c/titanic, aby pobrać \n * train.csv i test.csv. \n\nZapisz je w katalogu datasets/titanic.","metadata":{}},{"cell_type":"code","source":"import os\nTITANIC_PATH = os.path.join(\"datasets\", \"titanic\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndef load_titanic_data(filename, titanic_path=TITANIC_PATH):\n    csv_path = os.path.join(titanic_path, filename)\n    return pd.read_csv(csv_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/titanic/train.csv')\ntest_data = pd.read_csv('../input/titanic/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Dane są już podzielone na zestaw treningowy i zestaw testów. \n* Jednak dane testowe nie zawierają etykiet: Twoim celem jest wyszkolenie najlepszego modelu, który możesz wykorzystać w danych treningowych, następnie dokonanie swoich przewidywań na danych testowych i przesłanie ich do Kaggle, aby zobaczyć ostateczny wynik.\n\nRzućmy okiem na kilka pierwszych rzędów zestawu treningowego:","metadata":{}},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The attributes have the following meaning:\n\n* Survived: that's the target, 0 means the passenger did not survive, while 1 means he/she survived.\n* Pclass: passenger class.\n* Name, Sex, Age: self-explanatory\n* SibSp: how many siblings & spouses of the passenger aboard the Titanic.\n* Parch: how many children & parents of the passenger aboard the Titanic.\n* Ticket: ticket id\n* Fare: price paid (in pounds)\n* Cabin: passenger's cabin number\n* Embarked: where the passenger embarked the Titanic\n* Let's get more info to see how much data is missing:","metadata":{}},{"cell_type":"code","source":"train_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Atrybuty **Age**, **Cabin** oraz **Embarked** są czasami zerowe (mniej niż 891 wartości bez wartości null), szczególnie w przypadku **Cabin** (77% ma wartość zerową). Zignorujemy teraz **Cabin** i skupimy się na reszcie. Atrybut **Age** ma około 19% wartości pustych, więc będziemy musieli zdecydować, co z nimi zrobić. Zastąpienie wartości null medianą wieku wydaje się uzasadnione.\n\nAtrybuty **Name** i **Ticket** mogą mieć pewną wartość, ale będą one nieco trudne do przekształcenia w użyteczne liczby. Na razie będziemy je ignorować.\n\nRzućmy okiem na atrybuty liczbowe:","metadata":{}},{"cell_type":"code","source":"train_data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data=train_data.drop('Cabin', axis=1)\ntest_data=test_data.drop('Cabin', axis=1)\n\ntrain_data['Age']=train_data['Age'].fillna(train_data['Age'].mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data=train_data.drop('Name', axis=1)\ntest_data=test_data.drop('Name', axis=1)\n\ntrain_data=train_data.drop('Ticket', axis=1)\ntest_data=test_data.drop('Ticket', axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Tylko 38% przeżyło: to wystarczająco blisko do 40%, więc **accuracy** będzie rozsądną miarą do oceny naszego modelu.","metadata":{}},{"cell_type":"markdown","source":"Sprawdźmy, czy etykiety przyjmują wartości 0 lub 1:","metadata":{}},{"cell_type":"code","source":"train_data.info()\ntrain_data['Survived'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nie zapomnij o etykietach:","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train_data, train_data['Survived'], test_size=0.20, random_state=42)\ny_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Teraz rzućmy okiem na wszystkie atrybuty kategoryczne:","metadata":{}},{"cell_type":"code","source":"X_train['Sex'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train['Embarked'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Atrybut **Embarked** mówi nam, gdzie pasażer zaokrętował: C = Cherbourg, Q = Queenstown, S = Southampton.\n\nTeraz zbudujmy nasze **pipeline** preprocessingu. \n\nWykorzystamy DataframeSelector aby wybrać określone atrybuty z DataFrame:","metadata":{}},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\n\n# A class to select numerical or categorical columns \n# since Scikit-Learn doesn't handle DataFrames yet\nclass DataFrameSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attribute_names):\n        self.attribute_names = attribute_names\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        return X[self.attribute_names]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Zbudujmy **pipeline** dla atrybutów numerycznych:","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\n\nnum_pipeline = Pipeline([\n        (\"select_numeric\", DataFrameSelector(['Pclass', 'Age', 'SibSp', 'Parch', 'Fare'])),\n        (\"imputer\", SimpleImputer(strategy=\"median\")),\n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_pipeline.fit_transform(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Będziemy także potrzebować imputera do kategorycznych kolumn  napisowych (zwykły Imputer nie działa na tych kolumnach):","metadata":{}},{"cell_type":"code","source":"# Inspired from stackoverflow.com/questions/25239958\nclass MostFrequentImputer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n                                        index=X.columns)\n        return self\n    def transform(self, X, y=None):\n        return X.fillna(self.most_frequent_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Teraz możemy zbudować **pipeline** dla atrybutów kategorycznych:","metadata":{}},{"cell_type":"code","source":"# from future_encoders import OneHotEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\ncat_pipeline = Pipeline([\n        (\"select_cat\", DataFrameSelector(['Sex', 'Embarked'])),\n        (\"imputer\", MostFrequentImputer()),\n        (\"cat_encoder\", OneHotEncoder(sparse=False, handle_unknown = 'ignore')),\n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_pipeline.fit_transform(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Na koniec połączmy powyższe podejścia:","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import FeatureUnion\npreprocess_pipeline = FeatureUnion(transformer_list=[\n        (\"num_pipeline\", num_pipeline),\n        (\"cat_pipeline\", cat_pipeline),\n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Teraz mamy fajny **pipeline** przetwarzania wstępnego, który pobiera dane wejściowe i zwraca dane wyjściowe złorzone z liczb, które możemy podać do dowolnego modelu uczenia maszynowego.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Zad\n\nRobimy StratifiedKFold i znajdujemy optymalne parametry dla\n\n* SVM z jądrem rbf\n* SVM z jądrem poly\n* SVM liniowego\n* Regresji logistycznej","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nkfold = StratifiedKFold(n_splits=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe = Pipeline([\n    ('preprocessing', preprocess_pipeline), \n    ('classifier', SVC(kernel='linear'))])\n\n\nparam_grid = {\n            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]\n}\n\ngrid_1 = GridSearchCV(pipe, param_grid, cv=kfold)\n\ngrid_1.fit(X_train, y_train)\ngrid_1.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe = Pipeline([\n    ('preprocessing', preprocess_pipeline),\n    ('classifier', SVC(kernel='poly'))])\n\nparam_grid = {\n            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]\n}\n\ngrid_2 = GridSearchCV(pipe, param_grid, cv=kfold)\n\ngrid_2.fit(X_train, y_train)\ngrid_2.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe = Pipeline([\n    ('preprocessing', preprocess_pipeline),\n    ('classifier', SVC(kernel='linear'))])\n\nparam_grid = {\n            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]\n}\n\ngrid_3 = GridSearchCV(pipe, param_grid, cv=kfold)\n\ngrid_3.fit(X_train, y_train)\ngrid_3.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\npipe = Pipeline([\n    ('preprocessing', preprocess_pipeline),\n    ('classifier', LogisticRegression())])\n\nparam_grid = {\n            'classifier__C': [0.001, 0.01, 0.1, 1, 10]\n}\n\ngrid_4 = GridSearchCV(pipe, param_grid, cv=kfold)\n\ngrid_4.fit(X_train, y_train)\ngrid_4.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import  metrics\n\n\nmodels = []\nmodels.append(('SVM linear', grid_1.best_estimator_))\nmodels.append(('SVM poly', grid_2.best_estimator_))\nmodels.append(('SVM linear', grid_3.best_estimator_))\nmodels.append(('Logistic regression', grid_4.best_estimator_))\n\n\nprecision_score = []\nrecall_score = []\nf1_score = []\naccuracy_score = []\nfor name, model in models:\n    print(name)\n    print(\"precision_score: {}\".format(metrics.precision_score(y_test, model.predict(X_test)) ))\n    print(\"recall_score: {}\".format( metrics.recall_score(y_test, model.predict(X_test)) ))\n    print(\"f1_score: {}\".format( metrics.f1_score(y_test, model.predict(X_test)) ))\n    print(\"accuracy_score: {}\".format( metrics.accuracy_score(y_test, model.predict(X_test)) ))\n    precision_score.append(metrics.precision_score(y_test, model.predict(X_test)))\n    recall_score.append(metrics.recall_score(y_test, model.predict(X_test)))\n    f1_score.append( metrics.f1_score(y_test, model.predict(X_test)))\n    accuracy_score.append(metrics.accuracy_score(y_test, model.predict(X_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nd = {'precision_score': precision_score, \n     'recall_score': recall_score, \n     'f1_score': f1_score,\n     'accuracy_score' : accuracy_score\n    }\ndf = pd.DataFrame(data=d)\ndf.insert(loc=0, column='Method', value=['SVM rbf', 'SVM poly', 'SVM linear', 'Logistic Regression'])\nprint(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred = grid_1.predict(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n        \"PassengerId\": test_data[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('./submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}